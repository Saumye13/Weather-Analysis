{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aE5R5m5avBxk",
        "TshL7fPd91nY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saumye13/Weather-Analysis/blob/main/Weather_Analysis_using_Parallelism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "import time\n",
        "import concurrent.futures"
      ],
      "metadata": {
        "id": "npiz_jqInB0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute only when do not want to use GPU\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
        "\n",
        "# Now TensorFlow will use only the CPU"
      ],
      "metadata": {
        "id": "hpqlwUBn4fRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import multiprocessing"
      ],
      "metadata": {
        "id": "LA6RYPHk4cuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check CPU information\n",
        "cpu_info = !cat /proc/cpuinfo\n",
        "cpu_info = '\\n'.join(cpu_info)\n",
        "print(\"CPU Info:\\n\", cpu_info)\n",
        "\n",
        "# Get the number of CPU threads\n",
        "num_cpu_threads = multiprocessing.cpu_count()\n",
        "print(\"\\nNumber of CPU threads:\", num_cpu_threads)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOe1-CdAU2le",
        "outputId": "625175f4-754b-4c43-e475-681af1a10043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Info:\n",
            " processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0xffffffff\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "\n",
            "Number of CPU threads: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "-W8kf8Na2NX-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f6bcd8-3138-48c3-c3fb-edd6432a0aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "fLmlCFoD23zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c1b8b6-8cc1-4acd-f0b7-7b4769cfcde1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "import tensorflow as tf\n",
        "if tf.test.gpu_device_name():\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    print(\"GPU is NOT available\")"
      ],
      "metadata": {
        "id": "XTjuwqWgnFLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f73553ca-98b9-42a7-9d6a-ca774b9e6d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is NOT available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Handling"
      ],
      "metadata": {
        "id": "u04wKlEMy0Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "target_variable = 'tempC'\n",
        "data = data[features + [target_variable]]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Split data into input (X) and target (y) variables\n",
        "X = []\n",
        "y = []\n",
        "sequence_length = 50\n",
        "\n",
        "for i in range(len(data) - sequence_length):\n",
        "    X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "    y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "5G8NFl1Eog6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "5XDziS8sPCrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c194f0d3-90b7-4a8e-9167-bddd9ab97093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96382, 50, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "CGxIQY11PIuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004dcf48-f123-4d39-d972-6b6248d48a8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96382,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1w38evYFzqE",
        "outputId": "0d2f47bb-d6aa-4444-91c3-efcf3f6c477e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72286, 50, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwovz19dF4Ji",
        "outputId": "2ffd322e-457c-434f-e3bc-9df2645c9c0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72286,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comapring Running Time on CPU and GPU"
      ],
      "metadata": {
        "id": "fMBFrI3ljyMm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYgMuzGCiTB4"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud7PlhbUFt5C",
        "outputId": "6d968dfa-8e62-4ad2-a64f-0d7257087265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50, 50)            12200     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50, 50)            0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 50)            20200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50, 50)            0         \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52651 (205.67 KB)\n",
            "Trainable params: 52651 (205.67 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CPU"
      ],
      "metadata": {
        "id": "eLL_i4bnqz68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on CPU\n",
        "with tf.device('/cpu:0'):\n",
        "    start_time_cpu = time.time()\n",
        "    history_cpu = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
        "    end_time_cpu = time.time()\n",
        "\n",
        "# Evaluate the model on CPU\n",
        "with tf.device('/cpu:0'):\n",
        "    y_pred_cpu = model.predict(X_test)\n",
        "    mse_cpu = mean_squared_error(y_test, y_pred_cpu)\n",
        "    print(\"Mean Squared Error (CPU):\", mse_cpu)\n",
        "    print(\"Time taken on CPU: {:.2f} seconds\".format(end_time_cpu - start_time_cpu))\n"
      ],
      "metadata": {
        "id": "E9eFgaJ4okfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b327f782-a12d-4736-acde-603ce6c39ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2259/2259 - 185s - loss: 0.0034 - val_loss: 8.0700e-04 - 185s/epoch - 82ms/step\n",
            "Epoch 2/10\n",
            "2259/2259 - 176s - loss: 0.0012 - val_loss: 5.6315e-04 - 176s/epoch - 78ms/step\n",
            "Epoch 3/10\n",
            "2259/2259 - 175s - loss: 7.7305e-04 - val_loss: 4.4086e-04 - 175s/epoch - 77ms/step\n",
            "Epoch 4/10\n",
            "2259/2259 - 174s - loss: 6.1895e-04 - val_loss: 2.7806e-04 - 174s/epoch - 77ms/step\n",
            "Epoch 5/10\n",
            "2259/2259 - 175s - loss: 5.1317e-04 - val_loss: 2.5189e-04 - 175s/epoch - 78ms/step\n",
            "Epoch 6/10\n",
            "2259/2259 - 174s - loss: 4.7255e-04 - val_loss: 2.1822e-04 - 174s/epoch - 77ms/step\n",
            "Epoch 7/10\n",
            "2259/2259 - 175s - loss: 4.3020e-04 - val_loss: 1.7577e-04 - 175s/epoch - 77ms/step\n",
            "Epoch 8/10\n",
            "2259/2259 - 174s - loss: 4.2471e-04 - val_loss: 2.0486e-04 - 174s/epoch - 77ms/step\n",
            "Epoch 9/10\n",
            "2259/2259 - 175s - loss: 4.0275e-04 - val_loss: 2.5391e-04 - 175s/epoch - 78ms/step\n",
            "Epoch 10/10\n",
            "2259/2259 - 174s - loss: 3.9205e-04 - val_loss: 1.4936e-04 - 174s/epoch - 77ms/step\n",
            "753/753 [==============================] - 19s 24ms/step\n",
            "Mean Squared Error (CPU): 0.0001493634758695171\n",
            "Time taken on CPU: 1767.67 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU"
      ],
      "metadata": {
        "id": "lw9un5aXq2CQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on GPU\n",
        "with tf.device('/GPU:0'):\n",
        "    start_time_gpu = time.time()\n",
        "    history_gpu = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
        "    end_time_gpu = time.time()\n",
        "\n",
        "# Evaluate the model on GPU\n",
        "with tf.device('/GPU:0'):\n",
        "    y_pred_gpu = model.predict(X_test)\n",
        "    mse_gpu = mean_squared_error(y_test, y_pred_gpu)\n",
        "    print(\"Mean Squared Error (GPU):\", mse_gpu)\n",
        "    print(\"Time taken on GPU: {:.2f} seconds\".format(end_time_gpu - start_time_gpu))\n"
      ],
      "metadata": {
        "id": "COJTIwnaomTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4de70f-2ed8-4851-9378-06ae88c375f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2260/2260 - 18s - loss: 8.7360e-04 - val_loss: 3.6659e-04 - 18s/epoch - 8ms/step\n",
            "Epoch 2/10\n",
            "2260/2260 - 17s - loss: 5.9986e-04 - val_loss: 3.3670e-04 - 17s/epoch - 8ms/step\n",
            "Epoch 3/10\n",
            "2260/2260 - 19s - loss: 5.3973e-04 - val_loss: 2.1989e-04 - 19s/epoch - 8ms/step\n",
            "Epoch 4/10\n",
            "2260/2260 - 17s - loss: 4.9361e-04 - val_loss: 1.7516e-04 - 17s/epoch - 8ms/step\n",
            "Epoch 5/10\n",
            "2260/2260 - 18s - loss: 4.6845e-04 - val_loss: 2.0474e-04 - 18s/epoch - 8ms/step\n",
            "Epoch 6/10\n",
            "2260/2260 - 22s - loss: 4.4861e-04 - val_loss: 1.9677e-04 - 22s/epoch - 10ms/step\n",
            "Epoch 7/10\n",
            "2260/2260 - 18s - loss: 4.3467e-04 - val_loss: 1.8360e-04 - 18s/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "2260/2260 - 18s - loss: 4.3367e-04 - val_loss: 2.0425e-04 - 18s/epoch - 8ms/step\n",
            "Epoch 9/10\n",
            "2260/2260 - 18s - loss: 4.2453e-04 - val_loss: 1.9720e-04 - 18s/epoch - 8ms/step\n",
            "Epoch 10/10\n",
            "2260/2260 - 18s - loss: 4.1256e-04 - val_loss: 2.2328e-04 - 18s/epoch - 8ms/step\n",
            "754/754 [==============================] - 4s 4ms/step\n",
            "Mean Squared Error (GPU): 0.00022327516529568216\n",
            "Time taken on GPU: 202.08 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paralleling Training Model on Multiple GPUs\n"
      ],
      "metadata": {
        "id": "ljtzguezj5G8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the distributed strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Define the LSTM model within the strategy's scope\n",
        "with strategy.scope():\n",
        "    # Define the LSTM model\n",
        "    model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjKS_1Gz0J5h",
        "outputId": "9c764238-6f25-4df2-acba-ef8eb7dc42f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the distributed strategy\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "# Define the LSTM model within the strategy's scope\n",
        "with strategy.scope():\n",
        "    # Define the LSTM model\n",
        "    model = Sequential([\n",
        "    LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50, return_sequences=True),\n",
        "    Dropout(0.2),\n",
        "    LSTM(units=50),\n",
        "    Dropout(0.2),\n",
        "    Dense(units=1)\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time_m_gpu = time.time()\n",
        "    history_m_gpu = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "    end_time_m_gpu = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred_m_gpu = model.predict(X_test)\n",
        "    mse_m_gpu = mean_squared_error(y_test, y_pred_m_gpu)\n",
        "    print(\"Mean Squared Error:\", mse_m_gpu)\n",
        "    print(\"Time taken on Multiple GPU: {:.2f} seconds\".format(end_time_m_gpu - start_time_m_gpu))\n"
      ],
      "metadata": {
        "id": "yksEcdJxo2wX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80dcfddd-da60-4208-ec5c-442bec799941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n",
            "Epoch 1/10\n",
            "2260/2260 [==============================] - 65s 27ms/step - loss: 0.0042 - val_loss: 8.9936e-04\n",
            "Epoch 2/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 0.0012 - val_loss: 3.5314e-04\n",
            "Epoch 3/10\n",
            "2260/2260 [==============================] - 26s 11ms/step - loss: 6.6823e-04 - val_loss: 2.3051e-04\n",
            "Epoch 4/10\n",
            "2260/2260 [==============================] - 25s 11ms/step - loss: 5.6425e-04 - val_loss: 2.4551e-04\n",
            "Epoch 5/10\n",
            "2260/2260 [==============================] - 25s 11ms/step - loss: 5.1157e-04 - val_loss: 2.2027e-04\n",
            "Epoch 6/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.7403e-04 - val_loss: 1.9500e-04\n",
            "Epoch 7/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.5973e-04 - val_loss: 2.1746e-04\n",
            "Epoch 8/10\n",
            "2260/2260 [==============================] - 25s 11ms/step - loss: 4.4274e-04 - val_loss: 2.3283e-04\n",
            "Epoch 9/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.3618e-04 - val_loss: 1.6495e-04\n",
            "Epoch 10/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.2746e-04 - val_loss: 1.9505e-04\n",
            "754/754 [==============================] - 4s 4ms/step\n",
            "Mean Squared Error: 0.0001950538578154465\n",
            "Time taken on Multiple GPU: 325.87 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "start_time_m_gpu = time.time()\n",
        "history_m_gpu = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "end_time_m_gpu = time.time()\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred_m_gpu = model.predict(X_test)\n",
        "mse_m_gpu = mean_squared_error(y_test, y_pred_m_gpu)\n",
        "print(\"Mean Squared Error:\", mse_m_gpu)\n",
        "print(\"Time taken on Multiple GPU: {:.2f} seconds\".format(end_time_m_gpu - start_time_m_gpu))"
      ],
      "metadata": {
        "id": "0LDPSMQ8qCKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c261c6e-76ee-4b9a-f59d-1a1cff310e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2260/2260 [==============================] - 29s 11ms/step - loss: 0.0040 - val_loss: 0.0014\n",
            "Epoch 2/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 0.0012 - val_loss: 3.5822e-04\n",
            "Epoch 3/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 6.8586e-04 - val_loss: 3.2943e-04\n",
            "Epoch 4/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 5.6491e-04 - val_loss: 2.2612e-04\n",
            "Epoch 5/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 5.1611e-04 - val_loss: 3.0820e-04\n",
            "Epoch 6/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.8201e-04 - val_loss: 1.8628e-04\n",
            "Epoch 7/10\n",
            "2260/2260 [==============================] - 25s 11ms/step - loss: 4.6078e-04 - val_loss: 2.1599e-04\n",
            "Epoch 8/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.4884e-04 - val_loss: 1.9496e-04\n",
            "Epoch 9/10\n",
            "2260/2260 [==============================] - 23s 10ms/step - loss: 4.4070e-04 - val_loss: 3.9716e-04\n",
            "Epoch 10/10\n",
            "2260/2260 [==============================] - 25s 11ms/step - loss: 4.2235e-04 - val_loss: 1.7570e-04\n",
            "754/754 [==============================] - 4s 4ms/step\n",
            "Mean Squared Error: 0.00017569615790697442\n",
            "Time taken on Multiple GPU: 239.48 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Threading (Sequence Length = 10)"
      ],
      "metadata": {
        "id": "IerMg08Br87A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    return mse, end_time - start_time"
      ],
      "metadata": {
        "id": "lhre5l5Ww8ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence Length = 10"
      ],
      "metadata": {
        "id": "KhHdWpJBzLTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "target_variable = 'tempC'\n",
        "data = data[features + [target_variable]]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Split data into input (X) and target (y) variables\n",
        "X = []\n",
        "y = []\n",
        "sequence_length = 10\n",
        "\n",
        "for i in range(len(data) - sequence_length):\n",
        "    X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "    y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "uzUHNeiMw-vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]"
      ],
      "metadata": {
        "id": "yvkjezCSxHyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Thread (Sequence Length = 10)"
      ],
      "metadata": {
        "id": "tZd_Cr6cx0pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without main Function"
      ],
      "metadata": {
        "id": "spcue93RyVDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a concurrent futures executor with 1 CPU threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
        "    # Submit tasks for each model configuration\n",
        "    futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "    # Collect results as they become available\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        config = futures[future]\n",
        "        mse, training_time = future.result()\n",
        "        print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZADxMZ-_yFG5",
        "outputId": "eef610f3-d141-46c5-e12a-d28079b1857c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 4s 5ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000171, Training Time: 264.32 seconds\n",
            "603/603 [==============================] - 4s 6ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000165, Training Time: 385.51 seconds\n",
            "603/603 [==============================] - 4s 5ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000159, Training Time: 324.47 seconds\n",
            "603/603 [==============================] - 6s 9ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000178, Training Time: 626.44 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With main function (Windows Interative Interpreter)"
      ],
      "metadata": {
        "id": "1Uia2jaYyhqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Set up a concurrent futures executor with 1 CPU threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
        "        # Submit tasks for each model configuration\n",
        "        futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "        # Collect results as they become available\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            config = futures[future]\n",
        "            mse, training_time = future.result()\n",
        "            print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgUsJqTuybfO",
        "outputId": "3a614721-63cf-4050-e57b-75d1e433e516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 3s 5ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000171, Training Time: 265.65 seconds\n",
            "603/603 [==============================] - 4s 6ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000203, Training Time: 377.64 seconds\n",
            "603/603 [==============================] - 4s 6ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000154, Training Time: 293.43 seconds\n",
            "603/603 [==============================] - 6s 8ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000160, Training Time: 565.44 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Threads (Sequence Length = 10)"
      ],
      "metadata": {
        "id": "r47JcZ1xx8oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without main Function"
      ],
      "metadata": {
        "id": "-gBz2Z4VxPSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a concurrent futures executor with 2 CPU threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    # Submit tasks for each model configuration\n",
        "    futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "    # Collect results as they become available\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        config = futures[future]\n",
        "        mse, training_time = future.result()\n",
        "        print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvZV54PXolMs",
        "outputId": "eef1cb48-a873-468a-ab18-71ced06d68ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 5s 6ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000221, Training Time: 333.40 seconds\n",
            "603/603 [==============================] - 6s 8ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000218, Training Time: 588.55 seconds\n",
            "603/603 [==============================] - 6s 8ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000172, Training Time: 448.21 seconds\n",
            "603/603 [==============================] - 7s 10ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000182, Training Time: 630.41 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With main function (Windows Interative Interpreter)"
      ],
      "metadata": {
        "id": "uz__LwcRsFvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "    features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "    target_variable = 'tempC'\n",
        "    data = data[features + [target_variable]]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Split data into input (X) and target (y) variables\n",
        "    X = []\n",
        "    y = []\n",
        "    sequence_length = 10\n",
        "\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "        y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define model configurations\n",
        "    model_configurations = [\n",
        "        {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "        {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "        {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "        {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "    ]\n",
        "\n",
        "    # Set up a concurrent futures executor with 2 CPU threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        # Submit tasks for each model configuration\n",
        "        futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "        # Collect results as they become available\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            config = futures[future]\n",
        "            mse, training_time = future.result()\n",
        "            print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mgoOzb6qAHC",
        "outputId": "d2cfd71f-e826-4808-84a8-8d435c2fdb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 19s 30ms/step\n",
            "603/603 [==============================] - 11s 15ms/step\n",
            "603/603 [==============================] - 14s 22ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000235, Training Time: 873.71 seconds\n",
            "603/603 [==============================] - 15s 20ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000165, Training Time: 1135.99 seconds\n",
            "603/603 [==============================] - 18s 28ms/step\n",
            "603/603 [==============================] - 12s 17ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000159, Training Time: 861.72 seconds\n",
            "603/603 [==============================] - 9s 10ms/step\n",
            "603/603 [==============================] - 7s 10ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000167, Training Time: 1054.20 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi Threading (Sequence Length = 50)"
      ],
      "metadata": {
        "id": "NM8HXDRE3a5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    return mse, end_time - start_time"
      ],
      "metadata": {
        "id": "P6RSmXLS3a5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequence Length = 50"
      ],
      "metadata": {
        "id": "OrgyNdlR3a5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "target_variable = 'tempC'\n",
        "data = data[features + [target_variable]]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Split data into input (X) and target (y) variables\n",
        "X = []\n",
        "y = []\n",
        "sequence_length = 50\n",
        "\n",
        "for i in range(len(data) - sequence_length):\n",
        "    X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "    y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "naPOAG1x3a5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]"
      ],
      "metadata": {
        "id": "2_rcp0AD3a5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Thread (Sequence Length = 50)"
      ],
      "metadata": {
        "id": "cb_dcgXQ3a5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without main Function"
      ],
      "metadata": {
        "id": "43Zp7pyK3a5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a concurrent futures executor with 1 CPU threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
        "    # Submit tasks for each model configuration\n",
        "    futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "    # Collect results as they become available\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        config = futures[future]\n",
        "        mse, training_time = future.result()\n",
        "        print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEQf1B1y3a5s",
        "outputId": "3f3e73fa-6c86-4e07-e1bb-2a8149381cfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 5s 8ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000206, Training Time: 504.81 seconds\n",
            "603/603 [==============================] - 9s 14ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000157, Training Time: 1045.75 seconds\n",
            "603/603 [==============================] - 8s 12ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000129, Training Time: 733.33 seconds\n",
            "603/603 [==============================] - 16s 25ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000250, Training Time: 1765.49 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With main function (Windows Interative Interpreter)"
      ],
      "metadata": {
        "id": "v_Lp03Ho3a5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # Set up a concurrent futures executor with 1 CPU threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
        "        # Submit tasks for each model configuration\n",
        "        futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "        # Collect results as they become available\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            config = futures[future]\n",
        "            mse, training_time = future.result()\n",
        "            print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alm5qcRu3a5s",
        "outputId": "fc9a8037-0f04-4aee-cb71-89022babd358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 6s 9ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000141, Training Time: 625.33 seconds\n",
            "603/603 [==============================] - 12s 18ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000192, Training Time: 1346.24 seconds\n",
            "603/603 [==============================] - 10s 16ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000136, Training Time: 924.94 seconds\n",
            "603/603 [==============================] - 22s 35ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000165, Training Time: 2186.51 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multiple Threads (Sequence Length = 50)"
      ],
      "metadata": {
        "id": "2rEuPFpb3a5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without main Function"
      ],
      "metadata": {
        "id": "gu8xujC43a5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a concurrent futures executor with 2 CPU threads\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    # Submit tasks for each model configuration\n",
        "    futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "    # Collect results as they become available\n",
        "    for future in concurrent.futures.as_completed(futures):\n",
        "        config = futures[future]\n",
        "        mse, training_time = future.result()\n",
        "        print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85f0467f-8612-4fa4-ed52-dea1fbccb1c9",
        "id": "RNu7DWzP3a5t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 10s 15ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000189, Training Time: 1110.11 seconds\n",
            "603/603 [==============================] - 19s 26ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000177, Training Time: 2253.31 seconds\n",
            "603/603 [==============================] - 14s 22ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000140, Training Time: 1527.48 seconds\n",
            "603/603 [==============================] - 21s 33ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000142, Training Time: 2334.52 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With main function (Windows Interative Interpreter)"
      ],
      "metadata": {
        "id": "ZRRty3gT3a5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "    features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "    target_variable = 'tempC'\n",
        "    data = data[features + [target_variable]]\n",
        "\n",
        "    # Scale the data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "    # Split data into input (X) and target (y) variables\n",
        "    X = []\n",
        "    y = []\n",
        "    sequence_length = 50\n",
        "\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "        y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define model configurations\n",
        "    model_configurations = [\n",
        "        {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "        {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "        {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "        {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "    ]\n",
        "\n",
        "    # Set up a concurrent futures executor with 2 CPU threads\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
        "        # Submit tasks for each model configuration\n",
        "        futures = {executor.submit(train_lstm_model, X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate']): config for config in model_configurations}\n",
        "\n",
        "        # Collect results as they become available\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            config = futures[future]\n",
        "            mse, training_time = future.result()\n",
        "            print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ed27f43-8684-4cc5-caba-7ddbb2526f3e",
        "id": "WsTUQdE13a5u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 7s 10ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000134, Training Time: 830.10 seconds\n",
            "603/603 [==============================] - 15s 22ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000155, Training Time: 1830.94 seconds\n",
            "603/603 [==============================] - 11s 17ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000208, Training Time: 1219.53 seconds\n",
            "603/603 [==============================] - 16s 25ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000156, Training Time: 1888.93 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Thread"
      ],
      "metadata": {
        "id": "C-EHmi29Zi6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    return mse, end_time - start_time"
      ],
      "metadata": {
        "id": "Hf3aZHx0aoGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('kanpur.csv', parse_dates=['date_time'], index_col='date_time')\n",
        "features = ['maxtempC', 'mintempC', 'cloudcover', 'humidity', 'tempC', 'sunHour', 'HeatIndexC', 'precipMM', 'pressure', 'windspeedKmph']\n",
        "target_variable = 'tempC'\n",
        "data = data[features + [target_variable]]\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Split data into input (X) and target (y) variables\n",
        "X = []\n",
        "y = []\n",
        "sequence_length = 10\n",
        "\n",
        "for i in range(len(data) - sequence_length):\n",
        "    X.append(scaled_data[i:i+sequence_length, :-1])\n",
        "    y.append(scaled_data[i+sequence_length, -1])\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "SpKpfVTIarNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]"
      ],
      "metadata": {
        "id": "gB8hX1MDatac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run each model configuration sequentially on a single thread\n",
        "for config in model_configurations:\n",
        "    mse, training_time = train_lstm_model(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'])\n",
        "    print(\"Model - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0L3Sn31ZlO8",
        "outputId": "daede81d-24fb-4c60-deae-bcc222107f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "603/603 [==============================] - 2s 3ms/step\n",
            "Model - Units: 50, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000187, Training Time: 170.02 seconds\n",
            "603/603 [==============================] - 3s 4ms/step\n",
            "Model - Units: 50, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000289, Training Time: 325.24 seconds\n",
            "603/603 [==============================] - 3s 4ms/step\n",
            "Model - Units: 100, Layers: 1, Dropout Rate: 0.2, Mean Squared Error: 0.000177, Training Time: 264.10 seconds\n",
            "603/603 [==============================] - 5s 7ms/step\n",
            "Model - Units: 100, Layers: 2, Dropout Rate: 0.2, Mean Squared Error: 0.000206, Training Time: 441.89 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Mutiple Models as Different Processes in Parallel"
      ],
      "metadata": {
        "id": "aE5R5m5avBxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Single CPU Process (Deadlock)"
      ],
      "metadata": {
        "id": "zGmmtsQ0OlRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    return mse, end_time - start_time\n"
      ],
      "metadata": {
        "id": "E7MDYK_ZOo-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "v6dFayQtwZrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Specifying Device as CPU"
      ],
      "metadata": {
        "id": "ZhpEfLtjvZPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate each model sequentially\n",
        "for i, config in enumerate(model_configurations):\n",
        "    print(f\"Training Model {i+1}...\")\n",
        "    mse, training_time = train_lstm_model(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'])\n",
        "    print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\\n\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "oHvXW9RgwbVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying Device as CPU"
      ],
      "metadata": {
        "id": "vlImR-8_vRuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Train and evaluate each model sequentially\n",
        "    for i, config in enumerate(model_configurations):\n",
        "        print(f\"Training Model {i+1}...\")\n",
        "        mse, training_time = train_lstm_model(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'])\n",
        "        print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\\n\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "frvm2eop2OHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple CPU Processes (Deadlock)"
      ],
      "metadata": {
        "id": "oJ5s21o2rqUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate, result_queue):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Put results in queue\n",
        "    result_queue.put((mse, end_time - start_time))\n"
      ],
      "metadata": {
        "id": "eZ45mbOQrtlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "4ZiWzjCoFk4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Specifying Device as CPU"
      ],
      "metadata": {
        "id": "WP2fRISqvn4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up a multiprocessing queue for collecting results\n",
        "result_queue = multiprocessing.Queue()\n",
        "\n",
        "# Create and start a process for each model\n",
        "processes = []\n",
        "for config in model_configurations:\n",
        "    process = multiprocessing.Process(target=train_lstm_model, args=(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'], result_queue))\n",
        "    processes.append(process)\n",
        "    process.start()\n",
        "\n",
        "# Wait for all processes to finish\n",
        "for process in processes:\n",
        "    process.join()\n",
        "\n",
        "# Collect and print results\n",
        "for i, config in enumerate(model_configurations):\n",
        "    mse, training_time = result_queue.get()\n",
        "    print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "C1N1ZWbjFnFV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "b8c4c139-1594-47dc-856e-5fc6004cb72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-b8e1608e4e80>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Wait for all processes to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Collect and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying Device as CPU"
      ],
      "metadata": {
        "id": "CF2aHEn5vr9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Set up a multiprocessing queue for collecting results\n",
        "    result_queue = multiprocessing.Queue()\n",
        "\n",
        "    # Create and start a process for each model\n",
        "    processes = []\n",
        "    for config in model_configurations:\n",
        "        process = multiprocessing.Process(target=train_lstm_model, args=(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'], result_queue))\n",
        "        processes.append(process)\n",
        "        process.start()\n",
        "\n",
        "    # Wait for all processes to finish\n",
        "    for process in processes:\n",
        "        process.join()\n",
        "\n",
        "    # Collect and print results\n",
        "    for i, config in enumerate(model_configurations):\n",
        "        mse, training_time = result_queue.get()\n",
        "        print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "25hj3bnm2keu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "f00dbb36-e41a-4c11-fcb7-7422881f2de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-daa8e098d3ac>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Wait for all processes to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mprocess\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Collect and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Multiple Models on Multiple Threads in Parallel"
      ],
      "metadata": {
        "id": "TshL7fPd91nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import queue"
      ],
      "metadata": {
        "id": "cilhPuea9rlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple CPU Threads (Does Not Work)"
      ],
      "metadata": {
        "id": "cxO-o6vNwMmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to define and train an LSTM model\n",
        "def train_lstm_model(X_train, y_train, X_test, y_test, units, layers, dropout_rate, result_queue):\n",
        "    # Define the LSTM model with dropout layers\n",
        "    model = Sequential()\n",
        "    for _ in range(layers - 1):\n",
        "        model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "        model.add(Dropout(dropout_rate))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "    # Put results in queue\n",
        "    result_queue.put((mse, end_time - start_time))\n"
      ],
      "metadata": {
        "id": "8DnLLM2P9nea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define model configurations\n",
        "model_configurations = [\n",
        "    {'units': 50, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 50, 'layers': 2, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 1, 'dropout_rate': 0.2},\n",
        "    {'units': 100, 'layers': 2, 'dropout_rate': 0.2}\n",
        "]\n"
      ],
      "metadata": {
        "id": "UsDxbrgp94pF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without Specifying Device as CPU"
      ],
      "metadata": {
        "id": "UQkdwRN5weLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up a threading queue for collecting results\n",
        "result_queue = queue.Queue()\n",
        "\n",
        "# Create and start a thread for each model\n",
        "threads = []\n",
        "for config in model_configurations:\n",
        "    thread = threading.Thread(target=train_lstm_model, args=(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'], result_queue))\n",
        "    threads.append(thread)\n",
        "    thread.start()\n",
        "\n",
        "# Wait for all threads to finish\n",
        "for thread in threads:\n",
        "    thread.join()\n",
        "\n",
        "# Collect and print results\n",
        "for i, config in enumerate(model_configurations):\n",
        "    mse, training_time = result_queue.get()\n",
        "    print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "CIisTSaf98ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "a7152acd-0061-4b22-ce78-6bf7f455762d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-88f4ee0ead4e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Wait for all threads to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Collect and print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying Device as CPU"
      ],
      "metadata": {
        "id": "ckdAqn0qwitb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/cpu:0'):\n",
        "    # Set up a threading queue for collecting results\n",
        "    result_queue = queue.Queue()\n",
        "\n",
        "    # Create and start a thread for each model\n",
        "    threads = []\n",
        "    for config in model_configurations:\n",
        "        thread = threading.Thread(target=train_lstm_model, args=(X_train, y_train, X_test, y_test, config['units'], config['layers'], config['dropout_rate'], result_queue))\n",
        "        threads.append(thread)\n",
        "        thread.start()\n",
        "\n",
        "    # Wait for all threads to finish\n",
        "    for thread in threads:\n",
        "        thread.join()\n",
        "\n",
        "    # Collect and print results\n",
        "    for i, config in enumerate(model_configurations):\n",
        "        mse, training_time = result_queue.get()\n",
        "        print(\"Model {} - Units: {}, Layers: {}, Dropout Rate: {}, Mean Squared Error: {:.6f}, Training Time: {:.2f} seconds\".format(i+1, config['units'], config['layers'], config['dropout_rate'], mse, training_time))\n"
      ],
      "metadata": {
        "id": "UhnZEbxB99g0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}